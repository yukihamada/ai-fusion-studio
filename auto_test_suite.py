#!/usr/bin/env python3
"""
å®Œå…¨è‡ªå‹•ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ
å…¨æ©Ÿèƒ½ã‚’åŒ…æ‹¬çš„ã«ãƒ†ã‚¹ãƒˆã—ã€ç”Ÿæˆã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®å“è³ªã‚‚è©•ä¾¡
"""

import os
import sys
import json
import time
import subprocess
import tempfile
import requests
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import signal


class AutoTestSuite:
    """å®Œå…¨è‡ªå‹•ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent
        self.test_results = {
            'timestamp': datetime.now().isoformat(),
            'tests': {},
            'overall_status': 'running'
        }
        self.web_process = None
        self.web_port = 8501
    
    def log(self, message, level="INFO"):
        """ãƒ­ã‚°å‡ºåŠ›"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        print(f"[{timestamp}] {level}: {message}")
    
    def run_unit_tests(self):
        """ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        self.log("ğŸ§ª ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆã‚’é–‹å§‹...")
        
        start_time = time.time()
        try:
            result = subprocess.run([
                sys.executable, "-m", "pytest", 
                "tests/", "-v", "--tb=short",
                "--json-report", "--json-report-file=test_results.json"
            ], capture_output=True, text=True, cwd=self.project_root, timeout=120)
            
            duration = time.time() - start_time
            success = result.returncode == 0
            
            # JSONãƒ¬ãƒãƒ¼ãƒˆèª­ã¿è¾¼ã¿
            json_path = self.project_root / "test_results.json"
            details = {}
            if json_path.exists():
                try:
                    with open(json_path, 'r') as f:
                        pytest_report = json.load(f)
                        summary = pytest_report.get('summary', {})
                        details = {
                            'total': summary.get('total', 0),
                            'passed': summary.get('passed', 0),
                            'failed': summary.get('failed', 0),
                            'skipped': summary.get('skipped', 0)
                        }
                except (json.JSONDecodeError, KeyError) as e:
                    self.log(f"JSONãƒ¬ãƒãƒ¼ãƒˆèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}", "WARNING")
                    # å‡ºåŠ›ã‹ã‚‰è§£æã‚’è©¦ã¿ã‚‹
                    import re
                    if result.stdout:
                        # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ã§çµæœã‚’æŠ½å‡º
                        passed_match = re.search(r'(\d+) passed', result.stdout)
                        failed_match = re.search(r'(\d+) failed', result.stdout)
                        skipped_match = re.search(r'(\d+) skipped', result.stdout)
                        
                        details = {
                            'passed': int(passed_match.group(1)) if passed_match else 0,
                            'failed': int(failed_match.group(1)) if failed_match else 0,
                            'skipped': int(skipped_match.group(1)) if skipped_match else 0
                        }
                        details['total'] = details['passed'] + details['failed'] + details['skipped']
            
            self.test_results['tests']['unit_tests'] = {
                'status': 'passed' if success else 'failed',
                'duration': duration,
                'details': details,
                'stdout': result.stdout,
                'stderr': result.stderr
            }
            
            self.log(f"âœ… ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆå®Œäº† ({duration:.1f}s)")
            return success
            
        except subprocess.TimeoutExpired:
            self.log("âŒ ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ", "ERROR")
            self.test_results['tests']['unit_tests'] = {
                'status': 'timeout',
                'duration': 120,
                'error': 'Test timeout after 120 seconds'
            }
            return False
        except Exception as e:
            self.log(f"âŒ ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}", "ERROR")
            self.test_results['tests']['unit_tests'] = {
                'status': 'error',
                'error': str(e)
            }
            return False
    
    def test_script_functionality(self):
        """ã‚¹ã‚¯ãƒªãƒ—ãƒˆæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""
        self.log("ğŸ”§ ã‚¹ã‚¯ãƒªãƒ—ãƒˆæ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆä¸­...")
        
        script_tests = {
            'merge_models_help': ['python', 'scripts/merge_models.py', '--help'],
            'evaluate_help': ['python', 'scripts/evaluate.py', '--help'],
            'experiment_tracker_help': ['python', 'scripts/experiment_tracker.py', '--help'],
            'quantize_help': ['python', 'scripts/quantize.py', '--help']
        }
        
        results = {}
        for test_name, cmd in script_tests.items():
            try:
                result = subprocess.run(cmd, capture_output=True, text=True, 
                                     cwd=self.project_root, timeout=30)
                success = result.returncode == 0
                results[test_name] = {
                    'status': 'passed' if success else 'failed',
                    'stdout': result.stdout[:500],  # æœ€åˆã®500æ–‡å­—ã®ã¿
                    'stderr': result.stderr[:500] if result.stderr else None
                }
                
                status = "âœ…" if success else "âŒ"
                self.log(f"{status} {test_name}")
                
            except subprocess.TimeoutExpired:
                results[test_name] = {'status': 'timeout'}
                self.log(f"â° {test_name} ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
            except Exception as e:
                results[test_name] = {'status': 'error', 'error': str(e)}
                self.log(f"âŒ {test_name} ã‚¨ãƒ©ãƒ¼: {e}")
        
        self.test_results['tests']['script_functionality'] = results
        all_passed = all(r['status'] == 'passed' for r in results.values())
        
        self.log(f"âœ… ã‚¹ã‚¯ãƒªãƒ—ãƒˆæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆå®Œäº†" if all_passed else "âš ï¸ ä¸€éƒ¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ†ã‚¹ãƒˆãŒå¤±æ•—")
        return all_passed
    
    def start_web_app(self):
        """Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•"""
        self.log("ğŸŒ Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’èµ·å‹•ä¸­...")
        
        try:
            # ãƒãƒ¼ãƒˆç¢ºèª
            if self.is_port_in_use(self.web_port):
                self.web_port = 8502
            
            self.web_process = subprocess.Popen([
                sys.executable, "-m", "streamlit", "run", 
                "web/app.py", "--server.port", str(self.web_port),
                "--server.headless", "true"
            ], cwd=self.project_root, stdout=subprocess.PIPE, 
               stderr=subprocess.PIPE, text=True)
            
            # èµ·å‹•å¾…æ©Ÿ
            for _ in range(30):  # 30ç§’å¾…æ©Ÿ
                if self.is_web_app_ready():
                    self.log(f"âœ… Webã‚¢ãƒ—ãƒªèµ·å‹•å®Œäº†: http://localhost:{self.web_port}")
                    return True
                time.sleep(1)
            
            self.log("âŒ Webã‚¢ãƒ—ãƒªèµ·å‹•ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ", "ERROR")
            return False
            
        except Exception as e:
            self.log(f"âŒ Webã‚¢ãƒ—ãƒªèµ·å‹•ã‚¨ãƒ©ãƒ¼: {e}", "ERROR")
            return False
    
    def is_port_in_use(self, port):
        """ãƒãƒ¼ãƒˆä½¿ç”¨ãƒã‚§ãƒƒã‚¯"""
        try:
            import socket
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                return s.connect_ex(('localhost', port)) == 0
        except:
            return False
    
    def is_web_app_ready(self):
        """Webã‚¢ãƒ—ãƒªæº–å‚™å®Œäº†ãƒã‚§ãƒƒã‚¯"""
        try:
            response = requests.get(f"http://localhost:{self.web_port}", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def test_web_app_endpoints(self):
        """Webã‚¢ãƒ—ãƒªã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãƒ†ã‚¹ãƒˆ"""
        if not self.is_web_app_ready():
            self.log("âŒ Webã‚¢ãƒ—ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“", "ERROR")
            return False
        
        self.log("ğŸŒ Webã‚¢ãƒ—ãƒªã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ãƒ†ã‚¹ãƒˆä¸­...")
        
        endpoints_to_test = [
            ('main_page', '/'),
            ('health_check', '/_stcore/health')
        ]
        
        results = {}
        for endpoint_name, path in endpoints_to_test:
            try:
                response = requests.get(f"http://localhost:{self.web_port}{path}", timeout=10)
                success = response.status_code == 200
                
                results[endpoint_name] = {
                    'status': 'passed' if success else 'failed',
                    'status_code': response.status_code,
                    'response_time': response.elapsed.total_seconds()
                }
                
                status = "âœ…" if success else "âŒ"
                self.log(f"{status} {endpoint_name} ({response.status_code})")
                
            except Exception as e:
                results[endpoint_name] = {
                    'status': 'error',
                    'error': str(e)
                }
                self.log(f"âŒ {endpoint_name} ã‚¨ãƒ©ãƒ¼: {e}")
        
        self.test_results['tests']['web_app_endpoints'] = results
        
        all_passed = all(r['status'] == 'passed' for r in results.values())
        self.log(f"âœ… Webã‚¢ãƒ—ãƒªãƒ†ã‚¹ãƒˆå®Œäº†" if all_passed else "âš ï¸ ä¸€éƒ¨Webã‚¢ãƒ—ãƒªãƒ†ã‚¹ãƒˆãŒå¤±æ•—")
        return all_passed
    
    def test_demo_workflow(self):
        """ãƒ‡ãƒ¢ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆ"""
        self.log("ğŸ¬ ãƒ‡ãƒ¢ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ãƒ†ã‚¹ãƒˆä¸­...")
        
        try:
            result = subprocess.run([
                sys.executable, "run_demo.py"
            ], input="n\n", capture_output=True, text=True, 
               cwd=self.project_root, timeout=60)
            
            success = result.returncode == 0 and "ğŸ‰ ãƒ‡ãƒ¢å®Ÿè¡Œå®Œäº†ï¼" in result.stdout
            
            self.test_results['tests']['demo_workflow'] = {
                'status': 'passed' if success else 'failed',
                'stdout': result.stdout,
                'stderr': result.stderr
            }
            
            if success:
                self.log("âœ… ãƒ‡ãƒ¢ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Œäº†")
                
                # ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
                expected_files = [
                    'configs/demo_config.yaml',
                    'experiments/experiments_db.json',
                    'experiments/demo_report.json'
                ]
                
                files_check = {}
                for file_path in expected_files:
                    full_path = self.project_root / file_path
                    exists = full_path.exists()
                    files_check[file_path] = exists
                    
                    status = "âœ…" if exists else "âŒ"
                    self.log(f"  {status} {file_path}")
                
                self.test_results['tests']['demo_workflow']['files_generated'] = files_check
                
                return success and all(files_check.values())
            else:
                self.log("âŒ ãƒ‡ãƒ¢ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å¤±æ•—", "ERROR")
                return False
                
        except subprocess.TimeoutExpired:
            self.log("âŒ ãƒ‡ãƒ¢ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ", "ERROR")
            self.test_results['tests']['demo_workflow'] = {
                'status': 'timeout',
                'error': 'Demo workflow timeout'
            }
            return False
        except Exception as e:
            self.log(f"âŒ ãƒ‡ãƒ¢ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ ã‚¨ãƒ©ãƒ¼: {e}", "ERROR")
            self.test_results['tests']['demo_workflow'] = {
                'status': 'error',
                'error': str(e)
            }
            return False
    
    def test_experiment_tracking(self):
        """å®Ÿé¨“è¿½è·¡ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ"""
        self.log("ğŸ“Š å®Ÿé¨“è¿½è·¡ã‚·ã‚¹ãƒ†ãƒ ã‚’ãƒ†ã‚¹ãƒˆä¸­...")
        
        try:
            # ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ç”Ÿæˆãƒ†ã‚¹ãƒˆ
            result = subprocess.run([
                sys.executable, "scripts/experiment_tracker.py",
                "--action", "leaderboard"
            ], capture_output=True, text=True, cwd=self.project_root, timeout=30)
            
            success = result.returncode == 0
            
            self.test_results['tests']['experiment_tracking'] = {
                'status': 'passed' if success else 'failed',
                'stdout': result.stdout,
                'stderr': result.stderr
            }
            
            if success:
                self.log("âœ… å®Ÿé¨“è¿½è·¡ã‚·ã‚¹ãƒ†ãƒ  ãƒ†ã‚¹ãƒˆå®Œäº†")
            else:
                self.log("âŒ å®Ÿé¨“è¿½è·¡ã‚·ã‚¹ãƒ†ãƒ  ãƒ†ã‚¹ãƒˆå¤±æ•—", "ERROR")
            
            return success
            
        except Exception as e:
            self.log(f"âŒ å®Ÿé¨“è¿½è·¡ã‚·ã‚¹ãƒ†ãƒ  ã‚¨ãƒ©ãƒ¼: {e}", "ERROR")
            self.test_results['tests']['experiment_tracking'] = {
                'status': 'error',
                'error': str(e)
            }
            return False
    
    def test_model_quality(self):
        """ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®å“è³ªãƒ†ã‚¹ãƒˆ"""
        self.log("ğŸ¤– ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®å“è³ªã‚’ãƒ†ã‚¹ãƒˆä¸­...")
        
        # ãƒ‡ãƒ¢ã§ç”Ÿæˆã•ã‚ŒãŸå®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
        experiments_db_path = self.project_root / "experiments" / "experiments_db.json"
        
        if not experiments_db_path.exists():
            self.log("âŒ å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“", "ERROR")
            return False
        
        try:
            with open(experiments_db_path, 'r') as f:
                experiments = json.load(f)
            
            quality_tests = {
                'has_experiments': len(experiments) > 0,
                'has_completed_experiments': any(exp.get('status') == 'completed' for exp in experiments),
                'has_evaluation_results': False,
                'has_quantization_info': False,
                'reasonable_scores': False
            }
            
            for exp in experiments:
                if exp.get('status') == 'completed':
                    # è©•ä¾¡çµæœã®å­˜åœ¨ç¢ºèª
                    if 'evaluations' in exp:
                        quality_tests['has_evaluation_results'] = True
                        
                        # ã‚¹ã‚³ã‚¢ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
                        if 'mt_bench_jp' in exp['evaluations']:
                            score = exp['evaluations']['mt_bench_jp'].get('overall_score', 0)
                            if 0 <= score <= 10:
                                quality_tests['reasonable_scores'] = True
                    
                    # é‡å­åŒ–æƒ…å ±ã®ç¢ºèª
                    if 'quantization' in exp:
                        quality_tests['has_quantization_info'] = True
            
            all_passed = all(quality_tests.values())
            
            self.test_results['tests']['model_quality'] = {
                'status': 'passed' if all_passed else 'failed',
                'details': quality_tests,
                'experiments_count': len(experiments)
            }
            
            if all_passed:
                self.log("âœ… ãƒ¢ãƒ‡ãƒ«å“è³ªãƒ†ã‚¹ãƒˆå®Œäº†")
            else:
                self.log("âš ï¸ ãƒ¢ãƒ‡ãƒ«å“è³ªãƒ†ã‚¹ãƒˆã§å•é¡Œã‚’æ¤œå‡º")
                for test, result in quality_tests.items():
                    if not result:
                        self.log(f"  âŒ {test}")
            
            return all_passed
            
        except Exception as e:
            self.log(f"âŒ ãƒ¢ãƒ‡ãƒ«å“è³ªãƒ†ã‚¹ãƒˆ ã‚¨ãƒ©ãƒ¼: {e}", "ERROR")
            self.test_results['tests']['model_quality'] = {
                'status': 'error',
                'error': str(e)
            }
            return False
    
    def test_performance_benchmarks(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
        self.log("âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚’å®Ÿè¡Œä¸­...")
        
        benchmarks = {}
        
        # ã‚¹ã‚¯ãƒªãƒ—ãƒˆèµ·å‹•æ™‚é–“
        scripts_to_benchmark = [
            'scripts/merge_models.py',
            'scripts/evaluate.py',
            'scripts/experiment_tracker.py'
        ]
        
        for script in scripts_to_benchmark:
            try:
                start_time = time.time()
                result = subprocess.run([
                    sys.executable, script, '--help'
                ], capture_output=True, timeout=15)
                end_time = time.time()
                
                benchmarks[script] = {
                    'startup_time': end_time - start_time,
                    'success': result.returncode == 0
                }
                
            except subprocess.TimeoutExpired:
                benchmarks[script] = {
                    'startup_time': 15.0,
                    'success': False,
                    'timeout': True
                }
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        try:
            import psutil
            process = psutil.Process()
            memory_usage = process.memory_info().rss / 1024 / 1024  # MB
            benchmarks['memory_usage_mb'] = memory_usage
        except:
            benchmarks['memory_usage_mb'] = 'unknown'
        
        self.test_results['tests']['performance_benchmarks'] = benchmarks
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŸºæº–ãƒã‚§ãƒƒã‚¯ï¼ˆã™ã¹ã¦10ç§’ä»¥å†…ï¼‰
        performance_ok = all(
            b.get('startup_time', 0) < 10.0 and b.get('success', False)
            for b in benchmarks.values() if isinstance(b, dict)
        )
        
        self.log(f"âœ… ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Œäº†" if performance_ok else "âš ï¸ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„ãŒå¿…è¦")
        return performance_ok
    
    def cleanup(self):
        """ãƒ†ã‚¹ãƒˆç’°å¢ƒã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        self.log("ğŸ§¹ ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­...")
        
        # Webã‚¢ãƒ—ãƒªã‚’åœæ­¢
        if self.web_process:
            try:
                self.web_process.terminate()
                self.web_process.wait(timeout=10)
                self.log("âœ… Webã‚¢ãƒ—ãƒªã‚’åœæ­¢ã—ã¾ã—ãŸ")
            except:
                try:
                    self.web_process.kill()
                    self.log("âš ï¸ Webã‚¢ãƒ—ãƒªã‚’å¼·åˆ¶çµ‚äº†ã—ã¾ã—ãŸ")
                except:
                    pass
        
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤
        temp_files = [
            'test_results.json',
            'configs/demo_config.yaml'
        ]
        
        for temp_file in temp_files:
            file_path = self.project_root / temp_file
            if file_path.exists():
                try:
                    file_path.unlink()
                    self.log(f"ğŸ—‘ï¸ å‰Šé™¤: {temp_file}")
                except:
                    pass
    
    def generate_comprehensive_report(self):
        """åŒ…æ‹¬çš„ãªãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        self.log("ğŸ“Š åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­...")
        
        self.test_results['overall_status'] = 'completed'
        
        # ç·åˆåˆ¤å®š
        test_statuses = []
        for test_name, test_result in self.test_results['tests'].items():
            if isinstance(test_result, dict):
                status = test_result.get('status', 'unknown')
                test_statuses.append(status == 'passed')
        
        overall_success = all(test_statuses) if test_statuses else False
        self.test_results['overall_success'] = overall_success
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        report_path = self.project_root / f"comprehensive_test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_path, 'w') as f:
            json.dump(self.test_results, f, indent=2, ensure_ascii=False)
        
        # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
        print("\n" + "="*80)
        print("ğŸ¯ AI Fusion Studio åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆ")
        print("="*80)
        
        print(f"ğŸ“… å®Ÿè¡Œæ—¥æ™‚: {self.test_results['timestamp']}")
        print(f"ğŸ“ ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«: {report_path}")
        print()
        
        # ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼
        for test_name, test_result in self.test_results['tests'].items():
            if isinstance(test_result, dict):
                status = test_result.get('status', 'unknown')
                status_icon = {
                    'passed': 'âœ…',
                    'failed': 'âŒ', 
                    'error': 'ğŸ’¥',
                    'timeout': 'â°',
                    'unknown': 'â“'
                }.get(status, 'â“')
                
                print(f"{status_icon} {test_name}: {status}")
                
                # è©³ç´°æƒ…å ±ãŒã‚ã‚Œã°è¡¨ç¤º
                if 'duration' in test_result:
                    print(f"   â±ï¸ å®Ÿè¡Œæ™‚é–“: {test_result['duration']:.2f}ç§’")
                
                if 'details' in test_result:
                    details = test_result['details']
                    if isinstance(details, dict):
                        for key, value in details.items():
                            print(f"   ğŸ“Š {key}: {value}")
        
        print("\n" + "="*80)
        if overall_success:
            print("ğŸ‰ ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼")
            print("ğŸš€ AI Fusion Studioã¯æœ¬ç•ªç’°å¢ƒã§ä½¿ç”¨ã™ã‚‹æº–å‚™ãŒã§ãã¦ã„ã¾ã™ã€‚")
        else:
            print("âš ï¸ ä¸€éƒ¨ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚")
            print("ğŸ”§ å•é¡Œã‚’ç¢ºèªã—ã¦ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚")
        print("="*80)
        
        return overall_success
    
    def run_all_tests(self):
        """ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
        self.log("ğŸš€ AI Fusion Studio åŒ…æ‹¬çš„è‡ªå‹•ãƒ†ã‚¹ãƒˆã‚’é–‹å§‹...")
        
        try:
            # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œé †åº
            test_sequence = [
                ("ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ", self.run_unit_tests),
                ("ã‚¹ã‚¯ãƒªãƒ—ãƒˆæ©Ÿèƒ½", self.test_script_functionality),
                ("ãƒ‡ãƒ¢ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼", self.test_demo_workflow),
                ("å®Ÿé¨“è¿½è·¡ã‚·ã‚¹ãƒ†ãƒ ", self.test_experiment_tracking),
                ("ãƒ¢ãƒ‡ãƒ«å“è³ª", self.test_model_quality),
                ("Webã‚¢ãƒ—ãƒªèµ·å‹•", self.start_web_app),
                ("Webã‚¢ãƒ—ãƒªã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ", self.test_web_app_endpoints),
                ("ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯", self.test_performance_benchmarks)
            ]
            
            for test_name, test_func in test_sequence:
                self.log(f"â–¶ï¸ {test_name} ã‚’å®Ÿè¡Œä¸­...")
                try:
                    result = test_func()
                    status = "âœ… æˆåŠŸ" if result else "âŒ å¤±æ•—"
                    self.log(f"{status}: {test_name}")
                except Exception as e:
                    self.log(f"ğŸ’¥ ã‚¨ãƒ©ãƒ¼: {test_name} - {e}", "ERROR")
            
            # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            overall_success = self.generate_comprehensive_report()
            
            return overall_success
            
        except KeyboardInterrupt:
            self.log("â¹ï¸ ãƒ†ã‚¹ãƒˆãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ", "WARN")
            return False
        finally:
            self.cleanup()


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    import argparse
    
    parser = argparse.ArgumentParser(description='AI Fusion Studio åŒ…æ‹¬çš„è‡ªå‹•ãƒ†ã‚¹ãƒˆ')
    parser.add_argument('--quick', action='store_true', help='ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆï¼ˆé‡ã„ãƒ†ã‚¹ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰')
    parser.add_argument('--web-only', action='store_true', help='Webã‚¢ãƒ—ãƒªãƒ†ã‚¹ãƒˆã®ã¿')
    args = parser.parse_args()
    
    suite = AutoTestSuite()
    
    # ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©è¨­å®šï¼ˆCtrl+Cå¯¾å¿œï¼‰
    def signal_handler(sig, frame):
        print("\nâ¹ï¸ ãƒ†ã‚¹ãƒˆã‚’ä¸­æ–­ä¸­...")
        suite.cleanup()
        sys.exit(1)
    
    signal.signal(signal.SIGINT, signal_handler)
    
    try:
        if args.web_only:
            # Webã‚¢ãƒ—ãƒªãƒ†ã‚¹ãƒˆã®ã¿
            suite.start_web_app()
            success = suite.test_web_app_endpoints()
        elif args.quick:
            # ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
            success = (suite.test_script_functionality() and 
                      suite.test_demo_workflow() and
                      suite.start_web_app() and
                      suite.test_web_app_endpoints())
        else:
            # å®Œå…¨ãƒ†ã‚¹ãƒˆ
            success = suite.run_all_tests()
        
        sys.exit(0 if success else 1)
        
    except Exception as e:
        print(f"\nğŸ’¥ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()